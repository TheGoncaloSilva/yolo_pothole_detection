{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tests and Analysis of YOLOv11s Model for Pothole Detection\n",
    "\n",
    "This documentation provides an overview of the tests and analysis conducted on the YOLOv11s model, which is designed for detecting potholes.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### Model Architecture\n",
    "- **YOLOv11s**: A compact version of the YOLO model, designed for efficient and accurate object detection.\n",
    "\n",
    "### Dataset\n",
    "- **Pothole Images**: A collection of images containing various types of potholes used for training and testing the model.\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Precision**: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "- **Recall**: The ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "- **F1 Score**: The weighted average of Precision and Recall.\n",
    "- **Mean Average Precision (mAP)**: The average precision across all classes.\n",
    "\n",
    "## Testing Procedure\n",
    "\n",
    "1. **Data Preprocessing**: Images are resized, normalized, and augmented to improve model robustness.\n",
    "2. **Model Training**: The YOLOv11s model is trained on the preprocessed dataset using a predefined training schedule.\n",
    "3. **Validation**: The model's performance is validated on a separate validation set to tune hyperparameters.\n",
    "4. **Testing**: The final model is tested on a test set to evaluate its performance using the aforementioned metrics.\n",
    "\n",
    "## Analysis\n",
    "\n",
    "- **Performance Metrics**: Detailed analysis of the model's precision, recall, F1 score, and mAP.\n",
    "- **Error Analysis**: Examination of false positives and false negatives to identify common failure cases.\n",
    "- **Inference Speed**: Measurement of the model's inference time to ensure real-time detection capabilities.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The YOLOv11s model demonstrates effective pothole detection with a balance between accuracy and speed. The analysis highlights the model's strengths and areas for improvement, providing insights for further development and deployment in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load model: PytorchStreamReader failed locating file data.pkl: file not found\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Import the yolov11 model\n",
    "try:\n",
    "    model = YOLO(\"pothole_model.pt\")  # Path to your model\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model: {e}\")\n",
    "\n",
    "# Function to perform pothole detections\n",
    "def pothole_detect(img_path):\n",
    "    \n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Print the type of model to debug\n",
    "    print(f\"Type of model: {type(model)}\")\n",
    "\n",
    "    # Pass the image through the detection model and get the result\n",
    "    detect_result = model(img)\n",
    "\n",
    "    # Plot the detections\n",
    "    detect_img = detect_result[0].plot()\n",
    "    \n",
    "    # Convert the image to RGB format\n",
    "    detect_img = cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return detect_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory where the custom images are stored\n",
    "custom_image_dir = '/home/l1gthzao/Desktop/FAA/yolo_pothole_detection/dataset/test/images'\n",
    "\n",
    "# Get the list of image files in the directory\n",
    "image_files = os.listdir(custom_image_dir)\n",
    "\n",
    "# Select 16 random images from the list\n",
    "selected_images = random.sample(image_files, 16)\n",
    "\n",
    "# Create a figure with subplots for each image\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\n",
    "\n",
    "# Iterate over the selected images and plot each one\n",
    "for i, img_file in enumerate(selected_images):\n",
    "    \n",
    "    # Compute the row and column index of the current subplot\n",
    "    row_idx = i // 4\n",
    "    col_idx = i % 4\n",
    "    \n",
    "    # Load the current image and run object detection\n",
    "    img_path = os.path.join(custom_image_dir, img_file)\n",
    "    detect_img = pothole_detect(img_path)\n",
    "    \n",
    "    # Plot the current image on the appropriate subplot\n",
    "    axes[row_idx, col_idx].imshow(detect_img)\n",
    "    axes[row_idx, col_idx].axis('off')\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pothole Detection](/home/l1gthzao/Desktop/FAA/yolo_pothole_detection/results/yolov11s_50_epochs/__results___files/__results___22_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "![Performance Metrics](/home/l1gthzao/Desktop/FAA/yolo_pothole_detection/results/yolov11s_50_epochs/__results___files/__results___14_0.png)\n",
    "\n",
    "#### Train Box Loss and Train Class Loss\n",
    "\n",
    "The train box loss and class loss decrease over the number of epochs (iterations over the dataset), but it is clear that the model hasn't converged yet. Perhaps training for more epochs would lead to better results. Apart from that, the fact that both losses are decreasing is a good sign that the model is learning and not overfitting.\n",
    "\n",
    "#### Metrics Precision and Recall\n",
    "\n",
    "The precision and recall metrics increased over the number of epochs and reached a plateau near the end of the training. This is a good sign that the model is capable of detecting true positives without missing many of them.\n",
    "\n",
    "#### Metrics mAP50 and mAP50-95 and DFL loss\n",
    "\n",
    "The mAP50 is at a level near 0.8 and converging, which is a good result for this model. The mAP50-95 ended up near 0.5, which is a significant difference from the mAP50. This means that the model still struggles with bounding the plotholes with high precision (high IoU thresholds). \n",
    "\n",
    "Aligning it with the DFL loss, which is low, but still not converging (specially on training), we can infer that the model could've learned better how to bound the potholes with higher precision.\n",
    "\n",
    "Solutions for this issue could include using data augmentation, since the model might not have seen enough examples of potholes in different conditions or adjusting anchor sizes so  that they better fit the potholes. It wouldn't be a good idea to increase the number of epochs, since a lot of metrics are already converging/near convergence.\n",
    "\n",
    "#### Validation Loss Metrics\n",
    "\n",
    "The validation loss metrics are all near convergence, but slighly higher than the training loss metrics (about 0.2 difference). Despite this deviation, we don't find it to be a significant issue, since the validation data is unseen by the model. If it was bigger, it would be a sign of overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
